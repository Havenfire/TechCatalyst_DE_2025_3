{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/codespace/.local/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [ollama]2m3/5\u001b[0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 ollama-0.5.2 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82aca8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smollm2:135m\n",
      "smollm:135m\n"
     ]
    }
   ],
   "source": [
    "for model in ollama.list()[\"models\"]:\n",
    "    print(model['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e7f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5c5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    model=\"smollm2:135m\",\n",
    "    messages=[\n",
    "        {'role':'user',\n",
    "         'content': 'why is the sky blue'}\n",
    "        \n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1fb2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky as we know it would be very dark and dim because of the way light travels. When sunlight passes through air it has to pass through molecules like nitrogen or oxygen in order to get into our eyes. These molecules absorb certain colors of light, which are not absorbed by other wavelengths that don't have a lot of color. So when we see a blue sky with some clouds present, there's more pigment than just the actual blue light itself.\\n\\nThink about it like this: if you look at any object in the sky – like trees or mountains – they appear to be different colors because their surface reflects less light from other wavelengths of light than our eyes do. The same thing happens with sunlight when we see the sky as it's illuminated by sunbeams, which are made up mainly of blue and green light.\\n\\nSo while the color is really just a result of how much pigment there is in the air around us, it can't be seen directly like being able to see an object on a black background – we have to look at the sky as it's illuminated by sunlight through our eyes or other instruments because that's where we get most of our information about what it looks like.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get('message').get(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0df3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3be17671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The sky as we know it would be very dark and dim because of the way light travels. When sunlight passes through air it has to pass through molecules like nitrogen or oxygen in order to get into our eyes. These molecules absorb certain colors of light, which are not absorbed by other wavelengths that don't have a lot of color. So when we see a blue sky with some clouds present, there's more pigment than just the actual blue light itself.\n",
       "\n",
       "Think about it like this: if you look at any object in the sky – like trees or mountains – they appear to be different colors because their surface reflects less light from other wavelengths of light than our eyes do. The same thing happens with sunlight when we see the sky as it's illuminated by sunbeams, which are made up mainly of blue and green light.\n",
       "\n",
       "So while the color is really just a result of how much pigment there is in the air around us, it can't be seen directly like being able to see an object on a black background – we have to look at the sky as it's illuminated by sunlight through our eyes or other instruments because that's where we get most of our information about what it looks like."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9941d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    model=\"smollm2:135m\",\n",
    "    messages=[\n",
    "        {'role':'system',\n",
    "         'content': 'You always answer in bullet points.'},\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content': 'what is gen ai?'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37935d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generative AI is an artificial intelligence (AI) system that generates new, unique outputs based on input data and rules or parameters. Unlike traditional programming languages where code can only be written by humans, Generative AI systems use machine learning algorithms to learn from vast amounts of data and adapt their output to different scenarios. This approach enables them to generate a wide range of novel combinations and patterns in a relatively short period.\n",
       "\n",
       "Generative AI is widely used in various fields such as natural language processing (NLP), computer vision, speech recognition, image generation, decision-making systems, robotics, and game development. It allows for the creation of highly flexible and adaptive models that can learn from data and adapt to new inputs without being explicitly programmed.\n",
       "\n",
       "A key feature of Generative AI is its ability to generate patterns in the data itself, rather than relying on predefined rules or programming language syntax. This makes it useful for tasks such as image generation, natural language processing (NLP), speech recognition, text generation, and robotics where complex problem-solving needs are required.\n",
       "\n",
       "Overall, Generative AI systems work by using machine learning algorithms to analyze data, learn from patterns, and adapt their output based on new inputs, enabling them to produce highly innovative solutions that can solve real-world problems or augment existing knowledge base processes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86e05872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LMM) is an artificial intelligence system that can be used to generate text data. LMMs are designed for tasks such as natural language processing (NLP), sentiment analysis, and rule-based writing. They use sophisticated algorithms and machine learning techniques to analyze vast amounts of text data and identify patterns, relationships, and anomalies.\n",
      "\n",
      "LMMs can process large volumes of text data at once, allowing them to generate responses in real-time or provide explanations for complex topics. They have the ability to recognize human language patterns, including grammar, syntax, vocabulary, and idioms, which enables them to create coherent writing that is clear, concise, and engaging.\n",
      "\n",
      "Some common examples of LMMs include chatbots, virtual assistants like Siri, Alexa, and Google Assistant, as well as text-based interfaces such as those found on social media platforms or online forums. By providing accurate information and explanations, LMMs aim to empower users with more effective communication skills and enhance their overall understanding of various topics."
     ]
    }
   ],
   "source": [
    "model = 'smollm2:135m'\n",
    "prompt = 'What is a large language model?'\n",
    "\n",
    "stream= chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17657d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatwithPT(prompt):\n",
    "    model = 'smollm2:135m'\n",
    "    stream= chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e67f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you find some creative ideas. Can you tell me what brings you up with this kind of thing? Are there any hobbies or interests that might interest someone in your corner? Perhaps we could explore something entirely new together, like a mystery novel set in a medieval village where people have been using special powers for the past 50 years!"
     ]
    }
   ],
   "source": [
    "chatwithPT(\"sup nerd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17be44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
