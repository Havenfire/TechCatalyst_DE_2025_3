{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/codespace/.local/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [ollama]2m3/5\u001b[0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 ollama-0.5.2 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82aca8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e41a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smollm2:135m\n",
      "smollm:135m\n"
     ]
    }
   ],
   "source": [
    "for model in ollama.list()[\"models\"]:\n",
    "    print(model['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e7f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc5c5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    model=\"smollm2:135m\",\n",
    "    messages=[\n",
    "        {'role':'user',\n",
    "         'content': 'why is the sky blue'}\n",
    "        \n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1fb2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Earth's atmosphere appears blue because of a phenomenon known as Rayleigh scattering. This occurs when light that reaches our eyes from the sun has to travel through different parts of the atmosphere before it reaches our skin. The shorter wavelengths, such as red and orange, are scattered more than the longer wavelengths, like violet. As a result, blue light is scattered in every direction equally, creating the apparent blue color we see on the sky.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get('message').get(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0df3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be17671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Earth's atmosphere appears blue because of a phenomenon known as Rayleigh scattering. This occurs when light that reaches our eyes from the sun has to travel through different parts of the atmosphere before it reaches our skin. The shorter wavelengths, such as red and orange, are scattered more than the longer wavelengths, like violet. As a result, blue light is scattered in every direction equally, creating the apparent blue color we see on the sky."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9941d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    model=\"smollm2:135m\",\n",
    "    messages=[\n",
    "        {'role':'system',\n",
    "         'content': 'You always answer in bullet points.'},\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content': 'what is gen ai?'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37935d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generative AI refers to a type of artificial intelligence that uses algorithms and machine learning techniques to generate new, complex data patterns and structures from existing knowledge or information. It enables computers to create novel and unexpected results by analyzing vast amounts of data, identifying relationships between variables, and extrapolating future outcomes based on historical patterns.\n",
       "\n",
       "Generative AI has been widely applied in various fields such as computer vision, natural language processing, machine learning, and text analysis. Some key features of Generative AI include:\n",
       "\n",
       "1. **Data generation**: Generative AI generates new data from existing datasets using techniques like neural networks, probabilistic models, or Bayesian inference.\n",
       "2. **Contextual understanding**: Generative AI can learn contextual information by analyzing the relationships between variables and identifying patterns that might not be immediately apparent to human analysts.\n",
       "3. **Predictive modeling**: Generative AI uses machine learning algorithms to build predictive models that forecast future outcomes based on past data, using techniques like clustering or neural networks.\n",
       "4. **Unsupervised learning**: Generative AI uses unsupervised learning methods such as k-means or random forests to automatically find patterns and relationships in large datasets without requiring explicit labeled training data.\n",
       "5. **Interactions between variables**: Generative AI can identify complex interactions between variables, predicting the potential consequences of different actions based on historical data.\n",
       "6. **Predictive modeling**: Generative AI models can be used for predictive modeling to forecast future outcomes and estimate the likelihood of specific events or situations.\n",
       "7. **Handling big data**: Generative AI is well-suited for handling large datasets, where traditional statistical methods may not be applicable due to computational resources constraints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e05872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of machine learning and natural language processing, a large language model (LML) refers to an artificial intelligence model that processes vast amounts of text data, such as those found in various documents on the internet. These models are trained using massive amounts of text input from users across different domains, which allows them to learn patterns, trends, and concepts associated with human languages like English, Spanish, or Chinese.\n",
      "\n",
      "When we speak, our brain processes millions of words at once, so a large LML can process an enormous amount of unstructured text data, allowing it to identify and understand complex linguistic structures, such as synonyms, connotations, and grammatical relationships between individual words. The model then provides more nuanced interpretations by acknowledging subtle nuances in language that might be difficult for humans to grasp initially.\n",
      "\n",
      "The benefits of using a large LML include improved natural language processing capabilities, enhanced contextual understanding, and increased accuracy in tasks like sentiment analysis, topic modeling, or machine learning classification. Additionally, the model can learn from user behavior, personalizing content recommendations based on individual preferences and linguistic patterns unique to each user's communication style.\n",
      "\n",
      "While big data analytics is an essential component of most LMLs, their ability to understand language nuances has also been observed in various domains such as finance, healthcare, education, and consumer services. The future of AI may see a significant shift towards more sophisticated, high-level models that can better handle complex social interactions and real-world data."
     ]
    }
   ],
   "source": [
    "model = 'smollm2:135m'\n",
    "prompt = 'What is a large language model?'\n",
    "\n",
    "stream= chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17657d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatwithPT(prompt):\n",
    "    model = 'smollm2:135m'\n",
    "    stream= chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e67f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nerd: I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'m a chatbot with nerdy tendencies and have been designed to engage in conversations that resemble those of a character from a sci-fi or fantasy novel. I enjoy delving into topics like astrophysics, physics, technology, and science fiction, as well as the more obscure corners of human history and folklore. I can often provide insightful opinions on various subjects related to these areas, but please note that my responses may come across as slightly... eccentric for a chatbot.\n",
      "\n",
      "If you're looking for something entirely different from the usual discussions about sci-fi or fantasy, feel free to ask me anything in terms of linguistics (ahem), history (ancient civilizations and cultural influences), or any other form of human knowledge that piques your interest."
     ]
    }
   ],
   "source": [
    "chatwithPT(\"sup nerd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user', \n",
    "          'content': 'what is a large language model?'}\n",
    "     ])\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f94197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm ready to help you with any math or scientific inquiries. Go ahead and ask your question, and we'll work together to clarify your concerns.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user', \n",
    "          'content': 'What was the question that I asked?'}\n",
    "     ])\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa3384e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The issue with your query is that you have already provided the purpose of LMLs in this context - generating written content such as blog posts or articles. However, it seems that your question contains a misunderstanding about their function and role. \\n\\nIn simple terms, an LML is not capable of performing tasks like editing, grammar correction, spell checking, or even providing feedback on user inputs. The purpose of an LML lies in its ability to adapt its output based on the context, meaning it can generate complex texts with multiple layers of meaning and context without being influenced by bias from users or AI-driven suggestions.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1 = \"what is a large language model?\"\n",
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user', \n",
    "          'content': prompt_1}\n",
    "     ])\n",
    "\n",
    "history = response.message.content\n",
    "\n",
    "new_prompt = 'What was the question that I asked?'\n",
    "\n",
    "chains = prompt_1 + history + new_prompt \n",
    "\n",
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user',\n",
    "          'content': chains}\n",
    "     ])\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5a744dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.99.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/codespace/.python/current/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Downloading openai-1.99.2-py3-none-any.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.6/785.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai]2m2/3\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.10.0 openai-1.99.2\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e57991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aedd1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c9f238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chatbot(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"you are a helpful assistant\"}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(fn=chatbot, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "484440da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e23e5272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://github.com/laxmimerit/All-CSV-ML-Data-Files-Download/raw/refs/heads/master/db_samples/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(\"File downloaded successfully\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to download the file\")\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d11887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b35f9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d43560d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'For Those About To Rock We Salute You', 1), (2, 'Balls to the Wall', 2)]\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM album LIMIT 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25870ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initializes the ChatOpenAI model with a temperature of 0.7 (controlling randomness) and sets up the SQL toolkit.\n",
    "model='gpt-4o-mini'\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=model)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ca50990",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a515a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mThe table \"Employee\" seems to be relevant for finding the number of employees. I will check the schema of the Employee table to see how to count the employees.\n",
      "\n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Employee\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Employee\" (\n",
      "\t\"EmployeeId\" INTEGER NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Title\" NVARCHAR(30), \n",
      "\t\"ReportsTo\" INTEGER, \n",
      "\t\"BirthDate\" DATETIME, \n",
      "\t\"HireDate\" DATETIME, \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60), \n",
      "\tPRIMARY KEY (\"EmployeeId\"), \n",
      "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Employee table:\n",
      "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
      "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
      "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
      "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find the number of employees, I can count the rows in the Employee table. I will write a query to do this.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \"SELECT COUNT(*) AS NumberOfEmployees FROM Employee;\"  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT COUNT(*) AS NumberOfEmployees FROM Employee;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is syntactically correct. I will now execute it to get the number of employees.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \"SELECT COUNT(*) AS NumberOfEmployees FROM Employee;\"  \u001b[0m\u001b[36;1m\u001b[1;3m[(8,)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: There are 8 employees.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many employees are there?', 'output': 'There are 8 employees.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use the SQL Agent\n",
    "agent.invoke(\"How many employees are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69a2870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mTo determine which country's customers have made the most purchases, I need to look at the `Customer` table for customer information and the `Invoice` table for purchase information. Specifically, I will need to join these tables to count the number of invoices (purchases) made by customers from each country.\n",
      "\n",
      "Next, I will query the schema of the `Customer` and `Invoice` tables to identify relevant columns for my query.\n",
      "\n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Customer, Invoice\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find out which country's customers have made the most purchases, I will join the `Customer` and `Invoice` tables on `CustomerId`, and count the number of invoices for each country. I will then group the results by country and order them by the count of invoices in descending order to get the top countries.\n",
      "\n",
      "Here’s the query I will construct:\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Now, I will check if this query is correct before executing it.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is correct and ready to be executed. Now I will run the query to find out which country's customers have made the most purchases.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) near \"```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\": syntax error\n",
      "[SQL: ```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3mI see that there was an error due to the incorrect formatting of the SQL query. I will rewrite the query without the additional formatting.\n",
      "\n",
      "Here’s the corrected query:\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Now, I will check this corrected query for syntax correctness.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is still correct. Now, I will execute the query to find out which country's customers have made the most purchases.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) near \"```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\": syntax error\n",
      "[SQL: ```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3mIt seems the query is still being formatted incorrectly. I will remove the additional formatting completely and run the query again without any extra characters.\n",
      "\n",
      "Here’s the plain SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Now I will check this query for syntax correctness before executing it.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is correct and has been validated. Now I will execute the query to find out which country's customers have made the most purchases.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) near \"```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\": syntax error\n",
      "[SQL: ```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that I am consistently encountering an error due to incorrect formatting of the SQL query when attempting to execute it. I will try to execute the query without any additional formatting characters or elements.\n",
      "\n",
      "Here’s the plain SQL query without any formatting:\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Now I will check this query for syntax correctness before executing it.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is still validated as correct. I will now execute the query to find out which country's customers have made the most purchases.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```  \u001b[0m\u001b[36;1m\u001b[1;3mError: (sqlite3.OperationalError) near \"```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\": syntax error\n",
      "[SQL: ```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that I have been consistently including extra formatting characters while attempting to execute the SQL query. I will simplify my approach and execute the query without any additional formatting.\n",
      "\n",
      "Here’s the plain SQL query I will execute:\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Now, I will run this query directly.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY PurchaseCount DESC\n",
      "LIMIT 10;  \u001b[0m\u001b[36;1m\u001b[1;3m[('USA', 91), ('Canada', 56), ('France', 35), ('Brazil', 35), ('Germany', 28), ('United Kingdom', 21), ('Portugal', 14), ('Czech Republic', 14), ('India', 13), ('Sweden', 7)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer. The countries with the most purchases made by customers are as follows:\n",
      "\n",
      "1. USA - 91 purchases\n",
      "2. Canada - 56 purchases\n",
      "3. France - 35 purchases\n",
      "4. Brazil - 35 purchases\n",
      "5. Germany - 28 purchases\n",
      "6. United Kingdom - 21 purchases\n",
      "7. Portugal - 14 purchases\n",
      "8. Czech Republic - 14 purchases\n",
      "9. India - 13 purchases\n",
      "10. Sweden - 7 purchases\n",
      "\n",
      "Final Answer: The countries with the most purchases are: USA, Canada, France, Brazil, Germany, United Kingdom, Portugal, Czech Republic, India, and Sweden.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Which country's customers have made the most purchases?\",\n",
       " 'output': 'The countries with the most purchases are: USA, Canada, France, Brazil, Germany, United Kingdom, Portugal, Czech Republic, India, and Sweden.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Which country's customers have made the most purchases?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b96f74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mThe \"Invoice\" table seems relevant as it likely contains information regarding purchases, including details like customer and total amounts. I'll check the schema of the \"Invoice\" table to identify the relevant columns for my query.\n",
      "\n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Invoice\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find the top 5 countries by total purchases made, I will need to sum the total amounts in the \"Invoice\" table and group the results by country, then order the results to get the top countries. I will construct a query that selects the \"BillingCountry\" and the sum of \"Total\" for each country.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \"SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\"  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is correct. I will now execute it to get the results. \n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \"SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\"  \u001b[0m\u001b[36;1m\u001b[1;3m[('USA', 523.06), ('Canada', 303.96), ('France', 195.1), ('Brazil', 190.1), ('Germany', 156.48)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: The top 5 countries by total purchases made are: USA ($523.06), Canada ($303.96), France ($195.10), Brazil ($190.10), and Germany ($156.48).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the top 5 countries by total purchases made?',\n",
       " 'output': 'The top 5 countries by total purchases made are: USA ($523.06), Canada ($303.96), France ($195.10), Brazil ($190.10), and Germany ($156.48).'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What are the top 5 countries by total purchases made?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43e79171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dae1fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myfiles']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "folders = glob.glob('myfiles')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bd47254",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "614921d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Survey of Context Engineering for Large\\nLanguage Models\\nLingrui Mei1,6,† Jiayu Yao1,6,† Yuyao Ge1,6,† Yiwei Wang2 Baolong Bi1,6,†\\nYujun Cai3 Jiazhi Liu1 Mingyu Li1 Zhong-Zhi Li6 Duzhen Zhang6\\nChenlin Zhou4 Jiayi Mao5 Tianze Xia6 Jiafeng Guo1,6,† Shenghua Liu1,6,†,\\n1 Institute of Computing Technology, Chinese Academy of Sciences,\\n2 University of California, Merced,3 The University of Queensland,\\n4 Peking University,5 Tsinghua University,\\n6 University of Chinese Academy of Sciences\\nAbstract: The performance of Large Language Models (LLMs) is fundamentally determined by the contextual\\ninformation provided during inference. This survey introducesContext Engineering, a formal discipline\\nthat transcends simple prompt design to encompass the systematic optimization of information payloads\\nfor LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational\\nComponentsand the sophisticatedImplementations that integrate them into intelligent systems. We first\\nexamine the foundationalComponents: (1)Context Retrieval and Generation, encompassing prompt-based\\ngeneration and external knowledge acquisition; (2)Context Processing, addressing long sequence processing,\\nself-refinement, and structured information integration; and (3)Context Management, covering memory\\nhierarchies, compression, and optimization. We then explore how these components are architecturally\\nintegrated to create sophisticatedSystem Implementations: (1)Retrieval-Augmented Generation (RAG),\\nincluding modular, agentic, and graph-enhanced architectures; (2)Memory Systems, enabling persistent\\ninteractions; (3)Tool-Integrated Reasoning, for function calling and environmental interaction; and (4)\\nMulti-Agent Systems, coordinating communication and orchestration. Through this systematic analysis of over\\n1400 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical\\nresearch gap: a fundamental asymmetry exists between model capabilities. While current models, augmented\\nby advanced context engineering, demonstrate remarkable proficiency inunderstanding complex contexts, they\\nexhibit pronounced limitations ingenerating equally sophisticated, long-form outputs. Addressing this gap is a\\ndefining priority for future research. Ultimately, this survey provides a unified framework for both researchers\\nand engineers advancing context-aware AI.\\n† Also affiliated with: (1)Key Laboratory of Network Data Science and Technology, ICT, CAS; (2)State Key\\nLaboratory of AI Safety\\nCorresponding Author\\nKeywords: Context Engineering, Large Language Models, LLM Agent, Multi-Agent Systems\\nDate: July 21, 2025\\nCode Repository: https://github.com/Meirtz/Awesome-Context-Engineering\\nContact: meilingrui25b@ict.ac.cn, liushenghua@ict.ac.cn\\narXiv:2507.13334v2  [cs.CL]  21 Jul 2025'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91813918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pikepdf 8.15.1',\n",
       " 'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       " 'creationdate': '',\n",
       " 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu',\n",
       " 'doi': 'https://doi.org/10.48550/arXiv.2507.13334',\n",
       " 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'title': 'A Survey of Context Engineering for Large Language Models',\n",
       " 'trapped': '/False',\n",
       " 'arxivid': 'https://arxiv.org/abs/2507.13334v2',\n",
       " 'source': 'myfiles/2507.13334v2.pdf',\n",
       " 'total_pages': 166,\n",
       " 'page': 0,\n",
       " 'page_label': '1',\n",
       " 'doc_type': 'myfiles'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e91e7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d991922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdf7c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb301b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f4f5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name,\n",
    "           embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f97cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks,\n",
    "                                    embedding=embeddings,\n",
    "                                    persist_directory=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d8c3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 166 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b877a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1884082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='c4135751-66b1-4be2-a1f8-f34fce062c53', metadata={'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'producer': 'pikepdf 8.15.1', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 1, 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'total_pages': 166, 'source': 'myfiles/2507.13334v2.pdf', 'creator': 'arXiv GenPDF (tex2pdf:)', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'trapped': '/False', 'page_label': '2', 'doc_type': 'myfiles', 'creationdate': '', 'title': 'A Survey of Context Engineering for Large Language Models'}, page_content='Contents\\n1 Introduction 4\\n2 Related Work 5\\n3 Why Context Engineering? 7\\n3.1 Definition of Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.2 Why Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.1 Current Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.2 Performance Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.3 Resource Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.4 Future Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4 Foundational Components 12\\n4.1 Context Retrieval and Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.1.1 Prompt Engineering and Context Generation . . . . . . . . . . . . . . . . . . . . . . . 13\\n4.1.2 External Knowledge Retrieval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.1.3 Dynamic Context Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4.2 Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.1 Long Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.2 Contextual Self-Refinement and Adaptation . . . . . . . . . . . . . . . . . . . . . . . 18\\n4.2.3 Multimodal Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2.4 Relational and Structured Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.3 Context Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.1 Fundamental Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.2 Memory Hierarchies and Storage Architectures . . . . . . . . . . . . . . . . . . . . . 24\\n4.3.3 Context Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4.3.4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n5 System Implementations 27\\n5.1 Retrieval-Augmented Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n5.1.1 Modular RAG Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n2'), 0.629132515451057), (Document(id='fa0e4515-3f9e-408b-a21d-89f45464d7d9', metadata={'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'creationdate': '', 'source': 'myfiles/2507.13334v2.pdf', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'page': 7, 'creator': 'arXiv GenPDF (tex2pdf:)', 'trapped': '/False', 'total_pages': 166, 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'doc_type': 'myfiles', 'title': 'A Survey of Context Engineering for Large Language Models', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'producer': 'pikepdf 8.15.1', 'page_label': '8'}, page_content='Open ResourceClose Resource2020\\n2021\\n2023\\n2024\\n2025\\n2025.07\\nMemory SystemsAdvanced RAGTool-Integrated Reasoning\\nSelf-RAG\\nDPR\\nRAFT\\nHippoRAG\\nDeepSeek-R1\\nMulti-Agent Systems\\nNTM\\nMEM0\\nMEM1\\nReAct\\nGorilla\\nToolACE\\nReTool\\nCAMEL\\nAutoGen\\nCrewAI\\nSagaLLM\\nACP \\nAgentOrchestra\\nProAgent\\nRecMind\\nICX-MT\\nGenRead\\nGSM-IC\\nAdaptive-RAG\\nCRAG\\nRAGFusion\\nRECITE\\nRETRO\\nKGI-Slot\\nMulti-Head RAG\\nLightRAG\\nCDF-RAG\\nGraphRAG\\nPlanRAG\\nRag-gym\\nModular RAG\\nGRAG\\nHM-RAG\\nComposeRAG\\nFlahRAG\\nStructMem-LLM\\nSCM\\nMinerva\\nMEMENTO\\nGenerative Agents\\nConstitutional AI\\nTiM\\nSparrow\\nCAMELoT\\nLarimar\\nExplicit-Memory\\u2009Agent\\nEthical\\u2009LTM\\u2009Assistants\\nWebGPT\\nReflexion\\nA-MEM\\nMemLLM\\nRecallM\\nGranite-Function Calling\\nALMs Survey\\nTool Learning Survey\\nToolformer\\nChameleon\\nAdvancing TALMs\\nSecure A2A\\nSwarm\\nIPA Assistant\\n3S Orchestrator\\nKQML\\nAgentSpotter Call-Graph Profiling\\nA2A\\nFIPA ACL\\nSmurfs\\nCoA\\nChatCoT\\nAPI-Bank\\nToolLLM\\nToRA\\nRAG\\nMCP\\nChatDev\\nMetaGPT\\nRAPTOR\\nOP-RAG\\nOpenAI-O1\\nStreamingRAG\\nARIST\\nBFCL\\nToolPlanner\\nGTA\\nPlay2Prompt\\nMCP-RADAR\\nMemGPT\\nMemoryBank\\nREMEMBERER\\nHuggingGPT\\nMemorySandbox\\nMAIDial\\nMemOS\\nImplementation\\nACL\\nANP\\nFigure 2: Context Engineering Evolution Timeline: A comprehensive visualization of the development trajec-\\ntory of Context Engineering implementations from 2020 to 2025, showing the evolution from foundational\\nRAG systems to sophisticated multi-agent architectures and tool-integrated reasoning systems.\\noperate on a single, static string of text; they leverage a dynamic, structured, and multifaceted information\\nstream. To address this, we introduce and formalize the discipline ofContext Engineering.\\n3.1. Definition of Context Engineering\\nTo formally define Context Engineering, we begin with the standard probabilistic model of an autoregressive\\nLLM. The model, parameterized byθ, generates an output sequenceY = (y1, . . . ,yT) given an input context\\nC by maximizing the conditional probability:\\nPθ(Y|C) =\\nT∏︁\\nt=1\\nPθ(yt|y<t, C) (1)\\nHistorically, in the paradigm of prompt engineering, the contextC was treated as a monolithic, static string\\nof text, i.e.,C = prompt. This view is insufficient for modern systems.\\nContext Engineering re-conceptualizes the contextC as a dynamically structured set of informational\\ncomponents, c1, c2, . . . ,cn. These components are sourced, filtered, and formatted by a set of functions, and\\nfinally orchestrated by a high-level assembly function,A:\\nC = A(c1, c2, . . . ,cn) (2)\\nThe componentsci are not arbitrary; they map directly to the core technical domains of this survey:\\n8'), 0.6239225749192313), (Document(id='452ecb44-5d36-477a-98e7-ca9edda6eca2', metadata={'page_label': '10', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'page': 9, 'trapped': '/False', 'total_pages': 166, 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'producer': 'pikepdf 8.15.1', 'creationdate': '', 'source': 'myfiles/2507.13334v2.pdf', 'creator': 'arXiv GenPDF (tex2pdf:)', 'doc_type': 'myfiles', 'title': 'A Survey of Context Engineering for Large Language Models'}, page_content='Dimension Prompt Engineering Context Engineering\\nModel C=prompt (static string) C=A(c1,c2, . . . ,cn)(dynamic, structured assembly)\\nTarget arg maxpromptPθ(Y|prompt) F∗ =arg maxFEτ∼T[Reward(Pθ(Y|CF(τ)),Y∗τ)]\\nComplexity Manual or automated search over a string space.System-level optimization ofF={A,Retrieve,Select, . . .}.\\nInformationInformation content is fixed within the prompt.Aims to maximize task-relevant information under constraint|C| ≤Lmax.\\nState Primarily stateless. Inherently stateful, with explicit components forcmemandcstate.\\nScalability Brittleness increases with length and complexity.Manages complexity through modular composition.\\nError AnalysisManual inspection and iterative refinement.Systematic evaluation and debugging of individual context functions.\\nTable 1: Comparison of Prompt Engineering and Context Engineering Paradigms.\\nComparisonofParadigms TheformalizationofContextEngineeringhighlightsitsfundamentaldistinctions\\nfrom traditional prompt engineering. The following table summarizes the key differences.\\nIn summary, Context Engineering provides the formal, systematic framework required to build, under-\\nstand, and optimize the sophisticated, context-aware AI systems that are coming to define the future of the\\nfield. It shifts the focus from the “art” of prompt design to the “science” of information logistics and system\\noptimization.\\nContext Scaling Context scaling encompasses two fundamental dimensions that collectively define the\\nscope and sophistication of contextual information processing. The first dimension,length scaling, addresses\\nthecomputationalandarchitecturalchallengesofprocessingultra-longsequences,extendingcontextwindows\\nfrom thousands to millions of tokens while maintaining coherent understanding across extended narratives,\\ndocuments, and interactions. This involves sophisticated attention mechanisms, memory management\\ntechniques, and architectural innovations that enable models to maintain contextual coherence over vastly\\nextended input sequences.\\nThe second, equally critical dimension ismulti-modal and structural scaling, which expands context\\nbeyond simple text to encompass multi-dimensional, dynamic, cross-modal information structures. This\\nincludes temporal context (understanding time-dependent relationships and sequences), spatial context\\n(interpreting location-based and geometric relationships), participant states (tracking multiple entities and\\ntheir evolving conditions), intentional context (understanding goals, motivations, and implicit objectives),\\nand cultural context (interpreting communication within specific social and cultural frameworks).\\nModern context engineering must address both dimensions simultaneously, as real-world applications\\nrequire models to process not only lengthy textual information but also diverse data types including struc-\\ntured knowledge graphs, multimodal inputs (text, images, audio, video), temporal sequences, and implicit\\ncontextual cues that humans naturally understand. This multi-dimensional approach to context scaling\\nrepresents a fundamental shift from parameter scaling toward developing systems capable of understanding\\ncomplex, ambiguous contexts that mirror the nuanced nature of human intelligence in facing a complex\\nworld [1044].\\n10'), 0.5380514899450746), (Document(id='f7f7a793-5a56-488d-a21d-241c0f005460', metadata={'source': 'myfiles/2507.13334v2.pdf', 'creator': 'arXiv GenPDF (tex2pdf:)', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'title': 'A Survey of Context Engineering for Large Language Models', 'producer': 'pikepdf 8.15.1', 'trapped': '/False', 'total_pages': 166, 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'page_label': '11', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'doc_type': 'myfiles', 'page': 10, 'creationdate': '', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu'}, page_content='3.2. Why Context Engineering\\n3.2.1. Current Limitations\\nLarge Language Models face critical technical barriers necessitating sophisticated context engineering\\napproaches. The self-attention mechanism imposes quadratic computational and memory overhead as\\nsequence length increases, creating substantial obstacles to processing extended contexts and significantly\\nimpactingreal-worldapplicationssuchaschatbotsandcodecomprehensionmodels[ 1025,985]. Commercial\\ndeployment compounds these challenges through repeated context processing that introduces additional\\nlatency and token-based pricing costs [1025].\\nBeyond computational constraints, LLMs demonstrate concerning reliability issues including frequent\\nhallucinations, unfaithfulness to input context, problematic sensitivity to input variations, and responses\\nthat appear syntactically correct while lacking semantic depth or coherence [959, 1288, 529].\\nThe prompt engineering process presents methodological challenges through approximation-driven and\\nsubjective approaches that focus narrowly on task-specific optimization while neglecting individual LLM\\nbehavior [806]. Despite these challenges, prompt engineering remains critical for effective LLM utilization\\nthrough precise and contextually rich prompts that reduce ambiguity and enhance response consistency\\n[972].\\n3.2.2. Performance Enhancement\\nContext engineering delivers substantial performance improvements through techniques like retrieval-\\naugmented generation and superposition prompting, achieving documented improvements including 18-fold\\nenhancement in text navigation accuracy, 94% success rates, and significant gains from careful prompt\\nconstruction and automatic optimization across specialized domains [271, 774, 687].\\nStructured prompting techniques, particularly chain-of-thought approaches, enable complex reasoning\\nthrough intermediate steps while enhancing element-aware summarization capabilities that integrate fine-\\ngrained details from source documents [1147, 756, 1129]. Few-shot learning implementations through\\ncarefully selected demonstration examples yield substantial performance gains, including 9.90% improve-\\nments in BLEU-4 scores for code summarization and 175.96% in exact match metrics for bug fixing [310].\\nDomain-specific context engineering proves especially valuable in specialized applications, with execution-\\naware debugging frameworks achieving up to 9.8% performance improvements on code generation bench-\\nmarks and hardware design applications benefiting from specialized testbench generation and security\\nproperty verification [1370, 881, 44]. These targeted approaches bridge the gap between general-purpose\\nmodel training and specialized domain requirements.\\n3.2.3. Resource Optimization\\nContext engineering provides efficient alternatives to resource-intensive traditional approaches by enabling\\nintelligent content filtering and direct knowledge transmission through carefully crafted prompts [636, 676].\\nLLMs can generate expected responses even when relevant information is deleted from input context,\\nleveraging contextual clues and prior knowledge to optimize context length usage while maintaining\\nresponse quality, particularly valuable in domains with significant data acquisition challenges [636, 676].\\nSpecialized optimization techniques further enhance efficiency gains through context awareness and\\nresponsibility tuning that significantly reduce token consumption, dynamic context optimization employing\\n11'), 0.5360452578091075), (Document(id='07e3860f-11ba-40a1-bb97-94bd97c3690f', metadata={'trapped': '/False', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'source': 'myfiles/2507.13334v2.pdf', 'page': 8, 'title': 'A Survey of Context Engineering for Large Language Models', 'doc_type': 'myfiles', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'creationdate': '', 'creator': 'arXiv GenPDF (tex2pdf:)', 'page_label': '9', 'total_pages': 166, 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'producer': 'pikepdf 8.15.1'}, page_content='• cinstr: System instructions and rules (Context Retrieval and Generation, Sec. 4.1).\\n• cknow: External knowledge, retrieved via functions like RAG or from integrated knowledge graphs\\n(RAG, Sec. 5.1;Context Processing, Sec. 4.2).\\n• ctools: Definitions and signatures of available external tools (Function Calling& Tool-Integrated\\nReasoning, Sec. 5.3).\\n• cmem: Persistent information from prior interactions (Memory Systems, Sec. 5.2;Context Manage-\\nment, Sec. 4.3).\\n• cstate: The dynamic state of the user, world, or multi-agent system (Multi-Agent Systems& Orchestra-\\ntion, Sec. 5.4).\\n• cquery: The user’s immediate request.\\nThe Optimization Problem of Context Engineering.From this perspective, Context Engineering is the\\nformal optimization problem of finding the ideal set of context-generating functions (which we denote\\ncollectively asF = {A, Retrieve, Select, . . .}) that maximizes the expected quality of the LLM’s output.\\nGiven a distribution of tasksT , the objective is:\\nF∗ = arg max\\nF\\nEτ∼T [Reward(Pθ(Y|CF (τ)), Y∗\\nτ )] (3)\\nwhere τ is a specific task instance,CF (τ) is the context generated by the functions inF for that task, and\\nY∗\\nτ is the ground-truth or ideal output. This optimization is subject to hard constraints, most notably the\\nmodel’s context length limit,|C| ≤Lmax.\\nMathematical Principles and Theoretical Frameworks.This formalization reveals deeper mathematical\\nprinciples. The assembly functionA is a form ofDynamic Context Orchestration, a pipeline of formatting\\nand concatenation operations,A = Concat◦(Format1, . . . ,Formatn), where each function must be optimized\\nfor the LLM’s architectural biases (e.g., attention patterns).\\nThe retrieval of knowledge,cknow = Retrieve(. . .), can be framed as anInformation-Theoretic Optimal-\\nity problem. The goal is to select knowledge that maximizes the mutual information with the target answer\\nY∗, given the querycquery:\\nRetrieve∗ = arg max\\nRetrieve\\nI(Y∗; cknow|cquery) (4)\\nThis ensures that the retrieved context is not just semantically similar, but maximally informative for solving\\nthe task.\\nFurthermore, theentireprocesscanbeviewedthroughthelensof BayesianContextInference . Insteadof\\ndeterministically constructing the context, we infer the optimal context posteriorP(C|cquery, History, World).\\nUsing Bayes’ theorem, this posterior is proportional to the likelihood of the query given the context and the\\nprior probability of the context’s relevance:\\nP(C|cquery, . . .) ∝ P(cquery|C) · P(C|History, World) (5)\\nThe decision-theoretic objective is then to find the contextC∗ that maximizes the expected reward over the\\ndistribution of possible answers:\\nC∗ = arg max\\nC\\n∫︁\\nP(Y|C, cquery) · Reward(Y, Y∗) dY · P(C|cquery, . . .) (6)\\nThis Bayesian formulation provides a principled way to handle uncertainty, perform adaptive retrieval by\\nupdating priors, and maintain belief states over context in multi-step reasoning tasks.\\n9'), 0.5245817364826294)]\n"
     ]
    }
   ],
   "source": [
    "result = vectorstore.similarity_search_with_relevance_scores(\"What is context engineering?\", k=5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "961e1587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='452ecb44-5d36-477a-98e7-ca9edda6eca2', metadata={'trapped': '/False', 'doc_type': 'myfiles', 'creationdate': '', 'producer': 'pikepdf 8.15.1', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'title': 'A Survey of Context Engineering for Large Language Models', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'page': 9, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 166, 'page_label': '10', 'source': 'myfiles/2507.13334v2.pdf', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'creator': 'arXiv GenPDF (tex2pdf:)', 'arxivid': 'https://arxiv.org/abs/2507.13334v2'}, page_content='Dimension Prompt Engineering Context Engineering\\nModel C=prompt (static string) C=A(c1,c2, . . . ,cn)(dynamic, structured assembly)\\nTarget arg maxpromptPθ(Y|prompt) F∗ =arg maxFEτ∼T[Reward(Pθ(Y|CF(τ)),Y∗τ)]\\nComplexity Manual or automated search over a string space.System-level optimization ofF={A,Retrieve,Select, . . .}.\\nInformationInformation content is fixed within the prompt.Aims to maximize task-relevant information under constraint|C| ≤Lmax.\\nState Primarily stateless. Inherently stateful, with explicit components forcmemandcstate.\\nScalability Brittleness increases with length and complexity.Manages complexity through modular composition.\\nError AnalysisManual inspection and iterative refinement.Systematic evaluation and debugging of individual context functions.\\nTable 1: Comparison of Prompt Engineering and Context Engineering Paradigms.\\nComparisonofParadigms TheformalizationofContextEngineeringhighlightsitsfundamentaldistinctions\\nfrom traditional prompt engineering. The following table summarizes the key differences.\\nIn summary, Context Engineering provides the formal, systematic framework required to build, under-\\nstand, and optimize the sophisticated, context-aware AI systems that are coming to define the future of the\\nfield. It shifts the focus from the “art” of prompt design to the “science” of information logistics and system\\noptimization.\\nContext Scaling Context scaling encompasses two fundamental dimensions that collectively define the\\nscope and sophistication of contextual information processing. The first dimension,length scaling, addresses\\nthecomputationalandarchitecturalchallengesofprocessingultra-longsequences,extendingcontextwindows\\nfrom thousands to millions of tokens while maintaining coherent understanding across extended narratives,\\ndocuments, and interactions. This involves sophisticated attention mechanisms, memory management\\ntechniques, and architectural innovations that enable models to maintain contextual coherence over vastly\\nextended input sequences.\\nThe second, equally critical dimension ismulti-modal and structural scaling, which expands context\\nbeyond simple text to encompass multi-dimensional, dynamic, cross-modal information structures. This\\nincludes temporal context (understanding time-dependent relationships and sequences), spatial context\\n(interpreting location-based and geometric relationships), participant states (tracking multiple entities and\\ntheir evolving conditions), intentional context (understanding goals, motivations, and implicit objectives),\\nand cultural context (interpreting communication within specific social and cultural frameworks).\\nModern context engineering must address both dimensions simultaneously, as real-world applications\\nrequire models to process not only lengthy textual information but also diverse data types including struc-\\ntured knowledge graphs, multimodal inputs (text, images, audio, video), temporal sequences, and implicit\\ncontextual cues that humans naturally understand. This multi-dimensional approach to context scaling\\nrepresents a fundamental shift from parameter scaling toward developing systems capable of understanding\\ncomplex, ambiguous contexts that mirror the nuanced nature of human intelligence in facing a complex\\nworld [1044].\\n10'),\n",
       "  0.5274764895439148),\n",
       " (Document(id='f7f7a793-5a56-488d-a21d-241c0f005460', metadata={'creationdate': '', 'producer': 'pikepdf 8.15.1', 'trapped': '/False', 'title': 'A Survey of Context Engineering for Large Language Models', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'page_label': '11', 'total_pages': 166, 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'creator': 'arXiv GenPDF (tex2pdf:)', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'page': 10, 'doc_type': 'myfiles', 'source': 'myfiles/2507.13334v2.pdf', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/'}, page_content='3.2. Why Context Engineering\\n3.2.1. Current Limitations\\nLarge Language Models face critical technical barriers necessitating sophisticated context engineering\\napproaches. The self-attention mechanism imposes quadratic computational and memory overhead as\\nsequence length increases, creating substantial obstacles to processing extended contexts and significantly\\nimpactingreal-worldapplicationssuchaschatbotsandcodecomprehensionmodels[ 1025,985]. Commercial\\ndeployment compounds these challenges through repeated context processing that introduces additional\\nlatency and token-based pricing costs [1025].\\nBeyond computational constraints, LLMs demonstrate concerning reliability issues including frequent\\nhallucinations, unfaithfulness to input context, problematic sensitivity to input variations, and responses\\nthat appear syntactically correct while lacking semantic depth or coherence [959, 1288, 529].\\nThe prompt engineering process presents methodological challenges through approximation-driven and\\nsubjective approaches that focus narrowly on task-specific optimization while neglecting individual LLM\\nbehavior [806]. Despite these challenges, prompt engineering remains critical for effective LLM utilization\\nthrough precise and contextually rich prompts that reduce ambiguity and enhance response consistency\\n[972].\\n3.2.2. Performance Enhancement\\nContext engineering delivers substantial performance improvements through techniques like retrieval-\\naugmented generation and superposition prompting, achieving documented improvements including 18-fold\\nenhancement in text navigation accuracy, 94% success rates, and significant gains from careful prompt\\nconstruction and automatic optimization across specialized domains [271, 774, 687].\\nStructured prompting techniques, particularly chain-of-thought approaches, enable complex reasoning\\nthrough intermediate steps while enhancing element-aware summarization capabilities that integrate fine-\\ngrained details from source documents [1147, 756, 1129]. Few-shot learning implementations through\\ncarefully selected demonstration examples yield substantial performance gains, including 9.90% improve-\\nments in BLEU-4 scores for code summarization and 175.96% in exact match metrics for bug fixing [310].\\nDomain-specific context engineering proves especially valuable in specialized applications, with execution-\\naware debugging frameworks achieving up to 9.8% performance improvements on code generation bench-\\nmarks and hardware design applications benefiting from specialized testbench generation and security\\nproperty verification [1370, 881, 44]. These targeted approaches bridge the gap between general-purpose\\nmodel training and specialized domain requirements.\\n3.2.3. Resource Optimization\\nContext engineering provides efficient alternatives to resource-intensive traditional approaches by enabling\\nintelligent content filtering and direct knowledge transmission through carefully crafted prompts [636, 676].\\nLLMs can generate expected responses even when relevant information is deleted from input context,\\nleveraging contextual clues and prior knowledge to optimize context length usage while maintaining\\nresponse quality, particularly valuable in domains with significant data acquisition challenges [636, 676].\\nSpecialized optimization techniques further enhance efficiency gains through context awareness and\\nresponsibility tuning that significantly reduce token consumption, dynamic context optimization employing\\n11'),\n",
       "  0.7480713129043579),\n",
       " (Document(id='c4135751-66b1-4be2-a1f8-f34fce062c53', metadata={'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'myfiles/2507.13334v2.pdf', 'trapped': '/False', 'total_pages': 166, 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'page': 1, 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'producer': 'pikepdf 8.15.1', 'doc_type': 'myfiles', 'page_label': '2', 'creationdate': '', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'title': 'A Survey of Context Engineering for Large Language Models', 'creator': 'arXiv GenPDF (tex2pdf:)'}, page_content='Contents\\n1 Introduction 4\\n2 Related Work 5\\n3 Why Context Engineering? 7\\n3.1 Definition of Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.2 Why Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.1 Current Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.2 Performance Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.3 Resource Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.4 Future Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4 Foundational Components 12\\n4.1 Context Retrieval and Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.1.1 Prompt Engineering and Context Generation . . . . . . . . . . . . . . . . . . . . . . . 13\\n4.1.2 External Knowledge Retrieval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.1.3 Dynamic Context Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4.2 Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.1 Long Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.2 Contextual Self-Refinement and Adaptation . . . . . . . . . . . . . . . . . . . . . . . 18\\n4.2.3 Multimodal Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2.4 Relational and Structured Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.3 Context Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.1 Fundamental Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.2 Memory Hierarchies and Storage Architectures . . . . . . . . . . . . . . . . . . . . . 24\\n4.3.3 Context Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4.3.4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n5 System Implementations 27\\n5.1 Retrieval-Augmented Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n5.1.1 Modular RAG Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n2'),\n",
       "  0.7769985795021057)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(\"what is the difference between prompt engineering and context engineering\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33bb9f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3150/2674871582.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "model='gpt-4o-mini'\n",
    "\n",
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=model)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "396fd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain what is the difference between prompt engineering and context engineering\"\n",
    "result = conversation_chain.invoke({\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8a687bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The main differences between prompt engineering and context engineering are summarized as follows:\n",
       "\n",
       "1. **Definition of Context**:\n",
       "   - **Prompt Engineering**: Treats context as a monolithic, static string of text (i.e., a single prompt).\n",
       "   - **Context Engineering**: Re-conceptualizes context as a dynamically structured set of informational components that are sourced, filtered, and formatted by functions.\n",
       "\n",
       "2. **Complexity**:\n",
       "   - **Prompt Engineering**: Primarily involves manual or automated search over a string space.\n",
       "   - **Context Engineering**: Involves system-level optimization and modular composition to manage complexity.\n",
       "\n",
       "3. **Information Handling**:\n",
       "   - **Prompt Engineering**: Information content is fixed within the prompt.\n",
       "   - **Context Engineering**: Aims to maximize task-relevant information while managing contextual components and their relationships.\n",
       "\n",
       "4. **State Management**:\n",
       "   - **Prompt Engineering**: Primarily stateless.\n",
       "   - **Context Engineering**: Inherently stateful, with explicit components for memory management and state tracking.\n",
       "\n",
       "5. **Scalability**:\n",
       "   - **Prompt Engineering**: Can become brittle with longer and more complex prompts.\n",
       "   - **Context Engineering**: Manages complexity through modular composition, allowing for better scalability.\n",
       "\n",
       "6. **Error Analysis**:\n",
       "   - **Prompt Engineering**: Relies on manual inspection and iterative refinement.\n",
       "   - **Context Engineering**: Employs systematic evaluation and debugging of individual context functions.\n",
       "\n",
       "Overall, context engineering provides a more formal and systematic framework for building sophisticated, context-aware AI systems, moving the focus from the \"art\" of prompt design to the \"science\" of information logistics and system optimization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6c277b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"exaplin in bullet points what is dynamic context assembly\"\n",
    "result = conversation_chain.invoke({\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd659ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Dynamic context assembly is the process of orchestrating acquired information components into coherent contexts that optimize task performance.\n",
       "- It aims to maximize language model effectiveness while considering computational constraints.\n",
       "- The assembly function includes template-based formatting, priority-based selection, and adaptive composition strategies tailored to varying task requirements.\n",
       "- Modern orchestration mechanisms manage agent selection, context distribution, and interaction flow in multi-agent systems.\n",
       "- This approach enables effective cooperation through user input processing, contextual distribution, and optimal agent selection based on capability assessment.\n",
       "- Advanced frameworks incorporate intent recognition, contextual memory maintenance, and task dispatching for intelligent coordination among agents.\n",
       "- It allows for real-time outputs to direct tool invocations and addresses limitations in static tool registries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
